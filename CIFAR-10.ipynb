{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 data set\n",
    "## Here are the classes in the dataset, as well as 10 random images from each:\n",
    "<img src=\"cifar-10-classes.jpg\" class=\"cifar-sample\" width = 600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.la\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yiyi/Google Drive/CS/Coursera/CIFAR-10/cifar-10-batches-py/data_batch_1'"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path_entry = [\"/Users/yiyi/Google Drive/CS/Coursera/CIFAR-10/cifar-10-batches-py/data_batch_1\",\n",
    "\"/Users/yiyi/Google Drive/CS/Coursera/CIFAR-10/cifar-10-batches-py/data_batch_2\",\n",
    "\"/Users/yiyi/Google Drive/CS/Coursera/CIFAR-10/cifar-10-batches-py/data_batch_3\",\n",
    "\"/Users/yiyi/Google Drive/CS/Coursera/CIFAR-10/cifar-10-batches-py/data_batch_4\",\n",
    "\"/Users/yiyi/Google Drive/CS/Coursera/CIFAR-10/cifar-10-batches-py/data_batch_5\"]\n",
    "path_entry = train_path_entry[0]\n",
    "path_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  (50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def preLoad(entry):\n",
    "    data_dict = unpickle(entry)\n",
    "    batch_label = data_dict[b'batch_label']\n",
    "    data = data_dict[b'data']\n",
    "    labels = data_dict[b'labels']\n",
    "    filenames = data_dict[b'filenames']\n",
    "    return data, labels\n",
    "\n",
    "def preProcess(path_entry, num_classes = 10):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for entry in path_entry:\n",
    "        temp_data, temp_labels = preLoad(entry)\n",
    "        data.append(temp_data)\n",
    "        labels.append(temp_labels)\n",
    "\n",
    "    data = np.array(data)/255.0\n",
    "    X =data.reshape(data.shape[0]*data.shape[1], 32, 32, 3)\n",
    "    print(\"X.shape = \", X.shape)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    Y = labels.reshape(labels.shape[0]*labels.shape[1], 1)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def getClassnames(names_entry):\n",
    "    # Label: retrive classnames from the label\n",
    "    with open(names_entry, 'rb') as file:\n",
    "        names = pickle.load(file, encoding='bytes')\n",
    "    label_names = names[b'label_names']\n",
    "    return label_names\n",
    "\n",
    "def showFig(ROWS, COLUMNS, data, labels, names_entry):\n",
    "    # randomly sample\n",
    "    indexList = random.sample([idx for idx in range(len(labels))], ROWS*COLUMNS)\n",
    "    label_names = getClassnames(names_entry)\n",
    "    \n",
    "    # Image: show figures with their classnames on top\n",
    "    fig, ax = plt.subplots(ROWS, COLUMNS, figsize=(COLUMNS*2,ROWS*2.5))\n",
    "    for index in range(ROWS*COLUMNS):\n",
    "        image = data[indexList[index], :]\n",
    "        colorR, colorG, colorB = [image[:1024].reshape(32, 32), image[1024:2048].reshape(32, 32), image[2048:].reshape(32, 32)]\n",
    "        image = np.zeros(shape = (32, 32, 3))\n",
    "        image = np.dstack((colorR,colorG,colorB))\n",
    "        ax[int(index/COLUMNS),  int(index%COLUMNS)].imshow(image)\n",
    "        ax[int(index/COLUMNS),  int(index%COLUMNS)].set_title(label_names[labels[indexList[index]]].decode(\"utf-8\"), fontsize = 20)\n",
    "        ax[int(index/COLUMNS),  int(index%COLUMNS)].axis('off')\n",
    "    \n",
    "    \n",
    "# names_entry = '/Users/yiyi/Google Drive/CS/Coursera/CIFAR-10/cifar-10-batches-py/batches.meta'\n",
    "# classnames = getClassnames(names_entry)\n",
    "# number_classes = len(classnames)\n",
    "# print(\"number_classes = \", number_classes)\n",
    "# showFig(10, 10, data, labels, names_entry)\n",
    "\n",
    "# X, Y = preProcess(train_path_entry)\n",
    "# Y = keras.utils.to_categorical(y, 10)\n",
    "# showFig(10, 10, data, labels, names_entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showFig(10, 10, data, labels, names_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  (50000, 32, 32, 3)\n",
      "Y.shape =  (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "X, Y = preProcess(train_path_entry)\n",
    "print(\"X.shape = \", X.shape)\n",
    "print(\"Y.shape = \", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def baseline_model():\n",
    "    # creat model \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\", input_shape=(32, 32, 3)))\n",
    "    model.add(MaxPooling2D(pool_size = (3, 3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(32, 32, 3)))\n",
    "    model.add(MaxPooling2D(pool_size = (3, 3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(3072, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10,  kernel_initializer = 'normal', activation = 'softmax'))\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 393s 8ms/step - loss: 1.5326 - acc: 0.4687\n",
      "Epoch 2/10\n",
      "41632/50000 [=======================>......] - ETA: 1:05 - loss: 1.2082 - acc: 0.5754"
     ]
    }
   ],
   "source": [
    "cifar_model = baseline_model()\n",
    "cifar_model.fit(X, Y, epochs = 10, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
